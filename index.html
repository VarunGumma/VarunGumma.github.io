<!DOCTYPE html>
<html lang="en">

<head>
  <title>Varun Gumma</title>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="blog, accent, Varun Gumma, jekyll">
  <meta name="author" content="">



  <meta name="description" content="">
  <link rel="alternate" type="application/rss+xml" title="Varun Gumma RSS" href="feed.xml" />

  <script>
    (function () {
      try {
        var t = localStorage.getItem('theme');
        if (!t) { t = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light'; }
        document.documentElement.setAttribute('data-theme', t);
      } catch (e) { }
    })();
  </script>

  <!-- Fonts and Icons -->

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=Libre+Franklin:ital,wght@0,300;0,400;0,500;0,600;0,700;0,800;1,400&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <!-- Styles -->
  <link rel="stylesheet" href="css/main.css">


  <!-- Facebook Open Graph -->
  <meta name="og:description" content="">
  <meta name="og:title" content="Varun Gumma">
  <meta name="og:url" content="https://varungumma.github.io/">
  <meta name="og:type" content="article">


  <!-- Twitter -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Varun Gumma">
  <meta name="twitter:description" content="">
  <meta name="twitter:url" content="https://varungumma.github.io/">

  <meta name="twitter:image" content="">

</head>

<body>
  <div class="wrapper">
    <div class="navbar container">

      <img id="ins-logo" src="images/Nanyang_Technological_University-Logo.wine.svg"
        alt="Nanyang Technological University logo" />

      <a id="author-name" class="alignable pull-left" href="https://varungumma.github.io">Varun Gumma</a>
      <ul id="navlist" class="alignable pull-right navbar-ul">
        <li class="alignable pull-left nav-list"><a href="index.html">About</a></li>
        <li class="alignable pull-left nav-list"><a href="publications.html">Publications</a></li>
        <li class="alignable pull-left nav-list"><a target="_blank" href="CV.pdf">Resume</a></li>
        <li class="alignable pull-left nav-list">
          <button id="theme-toggle" class="theme-toggle" aria-label="Toggle theme" title="Toggle theme">
            <i class="fas fa-moon"></i>
          </button>
        </li>
      </ul>
    </div>
    <div style="clear:both"></div>
    <hr>

    <div class="container content">

      <div class="social-icons-sidebar" aria-label="Social links"
        style="position: fixed; right: 30px; top: 50%; transform: translateY(-50%); display: flex; flex-direction: column; gap: 28px; z-index: 100;">
        <a href="mailto:varun230999@gmail.com" target="_blank"><i class="fas fa-envelope ai-lg"
            style="font-size: 2.2rem;"></i></a>
        <a href="https://scholar.google.com/citations?user=tqDhGbwAAAAJ&hl=en" target="_blank"><i
            class="ai ai-google-scholar ai-lg" style="font-size: 2.2rem;"></i></a>
        <a href="https://www.semanticscholar.org/author/Varun-Gumma/2140408530" target="_blank"><i
            class="ai ai-semantic-scholar ai-lg" style="font-size: 2.2rem;"></i></a>
        <a href="https://github.com/VarunGumma" target="_blank"><i class="fab fa-github ai-lg"
            style="font-size: 2.2rem;"></i></a>
        <a href="https://x.com/VarunGumma23" target="_blank"><i class="fab fa-twitter ai-lg"
            style="font-size: 2.2rem;"></i></a>
      </div>

      <p><img class="profile-picture" src="images/profile_pic.jpg" alt="Portrait of Varun Gumma" /></p>

      <p>Heyüëã! I am Varun, a first-year PhD student in the School of Electrical and Electronic Engineering at <a
          href="https://www.ntu.edu.sg/" target="_blank">Nanyang
          Technological
          University</a>, advised by <a href="https://soujanyaporia.github.io" target="_blank">Prof. Soujanya
          Poria</a>.
        Previously, I was a Pre-Doctoral SCAI-Center Fellow at Microsoft Research India, where I was mentored by <a
          href="https://www.microsoft.com/en-us/research/people/kalikab/" target="_blank">Dr. Kalika Bali</a> and <a
          href="https://www.microsoft.com/en-us/research/people/susitara/" target="_blank">Dr. Sunayana Sitaram</a>.
        Prior to that, I completed my M.Tech at <a href="https://www.iitm.ac.in/" target="_blank">IIT Madras</a>,
        co-advised by <a href="https://prajdabre.github.io/" target="_blank">Dr. Raj Dabre</a> and <a
          href="https://www.cse.iitm.ac.in/~miteshk/" target="_blank">Prof. Mitesh Khapra</a>, and earlier earned my
        B.E. in Computer Science (with a Minor in Physics) from <a href="https://www.bits-pilani.ac.in/hyderabad/"
          target="_blank">BITS Hyderabad</a>.</p>

      <!-- <h2 id="research-interests">Research Interests</h2>

      <p>I am broadly interested in Natural Language Processing (NLP), particularly in areas such as Multilinguality
        combined with Machine Translation, Model Efficiency, Reasoning, and the Evaluation of Large Language Models. My
        research encompasses several specific areas and research questions:</p>

      <p><strong> üóé Document-Level Machine Translation</strong> How can we design or adapt existing Machine Translation
        models to translate entire documents reliably and efficiently? In a <a
          href="https://arxiv.org/abs/2408.11382">recent study</a>, I explored a rudimentary approach of replacing the
        Positional Embeddings of a standard pretrained Transformer with ones that facilitate length-generalization. This
        method demonstrated significant improvements in long-context understanding and generation with minimal
        fine-tuning. A subsequent question I am exploring is: how can we develop suitable evaluation metrics for
        document-level translation that effectively capture the task's nuances and provide a more reliable measure of
        model performance? Emphasis is placed on addressing issues such as "translationese" and "coreference-resolution"
        that challenge current metrics. With the prevalence of Large Language Models (LLMs) and Instruction-Tuning, it
        is also intriguing to investigate how these challenges can be addressed through "steerable" generation
        techniques in LLMs.</p>

      <p><strong>‚öôÔ∏è Model Efficiency</strong> My interest in model efficiency began with my <a
          href="https://aclanthology.org/2023.eamt-1.11/">Master's Thesis</a> on Knowledge Distillation for Multilingual
        Machine Translation models, where I investigated the impact of architectural variants like Extreme Parameter
        Sharing, Language-Specific Parameter Augmentation, and the Width-vs-Height trade-off on model performance,
        achieving gains with minimal parameter overhead (<a
          href="https://github.com/VarunGumma/fairseq/">framework</a>). With the advent of LLMs, I am now interested in
        exploring techniques such as Adaptive Tokenization, KV-Cache Compression, Mixture-of-Experts, and Efficient
        Long-Range Attention mechanisms to make LLM training and inference faster and less computationally expensive.
      </p>

      <p><strong>‚öñÔ∏è Evaluations</strong> The extensive use of internet data for training LLMs has led to "contamination"
        in standard benchmarks (<a href="https://arxiv.org/abs/2410.16186">EvalEval 2024</a>). Therefore, it is
        essential to continuously develop evaluation benchmarks and metrics that enable a holistic assessment of these
        models. Standard metrics are inadequate for multi-dimensional assessments of creative and open-ended
        generations, making LLM-based evaluators a preferred choice. However, our previous work reveals a clear
        disparity in the performance of LLM-based evaluators across languages, tasks, and perturbations (<a
          href="https://aclanthology.org/2024.findings-eacl.71/">EACL 2024</a>, <a
          href="https://aclanthology.org/2024.findings-naacl.148/">NAACL 2024</a>, <a
          href="https://arxiv.org/abs/2406.15053">EMNLP 2024</a>, <a href="https://arxiv.org/abs/2410.13671">ArXiv
          2024</a>). Thus, developing robust and "rational" multilingual evaluators is crucial. I believe that enhancing
        LLMs with strong reasoning abilities could significantly improve the reliability and interpretability of
        evaluations, and I am keen to explore how to build and "meta-evaluate" such models that can reason over outputs
        and offer a more robust assessment.</p> -->

      <!-- <p>I am broadly interested in Natural Language Processing (NLP), mainly towards Multilinguality clubbed with
        Machine Translation, Model Efficiency, Reasoning and Evaluation of Large Language Models. Some specific areas
        and Research Questions I am interested in are:</p>

      <p><strong> üóé Document-Level Machine Translation</strong> How can we build or modify exsisting Machine
        Translation models to translate entire documents reliablely and efficently? In a <a
          href="https://arxiv.org/abs/2408.11382"> recent work</a>, I explored a rudimentary of switching out Positional
        Embeddings of a standard pretrained Transformer with ones that favour length-generalization and showed that it
        can lead to significant improvements in long-context understanding and generation with minimal finetuning. I
        consequent question I am
        pondering on is how can we develop suitable evaluation metrics for document-level translation that can capture
        the nuances of the task and provide a more reliable measure of model performance, with more emphasis on the
        mitigating "translationese" and "coreference-resolution" issues that plague current metrics. With the ubiquity
        of Large
        Language Models (LLMs) and Instruction-Tuning, it would be interesting to also explore how much of these
        problems can be solved by LLMs with "Steerable"
        Generations.
      </p>

      <p><strong>‚öôÔ∏è Model Efficiency</strong> I was first introduced to this problem when I was working on my
        <a href="https://aclanthology.org/2023.eamt-1.11/">Master's Thesis</a> on Knowledge Distillation for
        Multilingual Machine Translation models, in which I explored how simple architectural variants like Extreme
        Parameter Sharing, Language-Specific Parameter Augmentation and Width-vs-Height trade-off can lead to various
        gains or
        drops in model performance at the cost of minimal parameter overhead (<a
          href="https://github.com/VarunGumma/fairseq/">framework</a>)
        Once again, with the advent of LLMs, I am interested to explore methods like Adaptive
        Tokenization, KV-Cache Compression, Mixture-of-Experts, and Efficient Long-Range Attention mechanisms to make
        training and inference of LLMs faster and computationally less expensive.
      </p>

      <p><strong>‚öñÔ∏è Evaluations</strong> The rampant consumption of data on the internet to train LLMs has lead to the
        "contamination" of standard banchmarks (<a href="https://arxiv.org/abs/2410.16186">EvalEval 2024</a>). Hence, it
        is vital to continually develop evaluation benchmarks
        and metrics for holistic evaluation of these models. Standard Metrics are unfit for a multi-dimensional
        assessment
        creative and open-ended generations, which is when we have to resort of LLM-based Evaluators. However, in our
        previous works we found that there is a clear disparity in the performance of LLM-based evaluators across
        languages, tasks and perturbations (<a href="https://aclanthology.org/2024.findings-eacl.71/">EACL 2024</a>, <a
          href="https://aclanthology.org/2024.findings-naacl.148/">NAACL 2024</a>, <a
          href="https://arxiv.org/abs/2406.15053">EMNLP 2024</a>, <a href="https://arxiv.org/abs/2410.13671">ArXiv
          2024</a>). Therefore, it is important to develop more robust and
        "rational"
        multilingual evaluators. I
        believe that inducing strong-reasoning abilities in LLMs could bolster the development of such evaluators, and I
        am
        interested in exploring how we can build and "meta-evaluate" such models that can reason over the output
        and provide a more
        reliable and interpretable evaluation.
      </p> -->

      <p>For a full list of my publications you can have a look <a href="publications.html">here</a>. Please feel free
        to reach out to me over <a href="mailto:varun230999@gmail.com">email</a> if you have any questions about my
        research, have suggestions or just want to chat, especially about Ph.D./MS opportunities and the applications
        cycle.</p>

      <h2 id="news">News</h2>

      <ul class="news-list" aria-label="Recent updates">
        <li>
          <p><strong>2025-09-26</strong>: üìú Preprint of my final work at MSRI, <a
              href="https://arxiv.org/abs/2509.21294">The Role of Synthetic Data in Multilingual,
              Multi-Cultural AI Systems: Lessons from Indic Languages</a>, is live!
        </li>
        <li>
          <p><strong>2025-08-11</strong>: ‚ñ∂Ô∏è Started my Ph.D at Nanyang Technological University @ School of EEE!</p>
        </li>
        <li>
          <p><strong>2025-08-18</strong>: ‚èπÔ∏è Completed my stint at Microsoft Research India! Grateful to all
            collaborators!</p>
        </li>
        <li>
          <p><strong>2025-04-29</strong>: üìú <a href="https://aclanthology.org/2025.naacl-long.366/">Towards Inducing
              Document-Level
              Abilities in MNMT Systems</a> has been accepted at
            NAACL 2025!
        </li>
        <li>
          <p><strong>2024-11-10</strong>: ‚úàÔ∏è Attending EMNLP 2024 at Miami, Florida to present our work, <a
              href="https://aclanthology.org/2024.emnlp-main.451/">Pariksha</a>.</p>
        </li>
        <li>
          <p><strong>2024-10-21</strong>: üìú The Report on Contamination of Multilingual Benchmarks has been accepted at
            EvalEval @ NEURIPS 2024. The
            <a href="https://arxiv.org/abs/2410.16186">preprint</a> is live!
          </p>
        </li>
        <li>
          <p><strong>2024-10-18</strong>: üìú Preprint of <a href="https://arxiv.org/abs/2410.13671">Health-Pariksha</a>
            is online. Do check it out, and more models are on the way! Also, an updated version of <a
              href="https://arxiv.org/abs/2408.11382">Towards Inducing Document-Level Abilities in MNMT Systems</a> is
            online, with an improved name, write up, evaluation set and <a
              href="https://github.com/VarunGumma/fairseq">framework</a>.</p>
        </li>
        <li>
          <p><strong>2024-08-10</strong>: ‚úàÔ∏è Attending ACL 2024 at Bangkok, Thailand (my first ever conference üéâ).</p>
        </li>
        <li>
          <p><strong>2023-07-31</strong>: ‚Ü™Ô∏è Converted from Intern to SCAI Center Fellow at Microsoft Research
            India</a>.
          </p>
        </li>
        <li>
          <p><strong>2023-05-22</strong>: ‚ñ∂Ô∏è Started my Internship at Microsoft Research India.</p>
        </li>
      </ul>

      <hr />

      <div class="credits"
        style="text-align: center; margin-top: 40px; margin-bottom: 10px; font-size: 0.7rem; line-height: 1.2;">
        <p style="margin: 2px 0; text-align: center;"><a href="https://github.com/ankitsultana">Theme by Ankit
            Sultana.</a></p>
        <p style="margin: 2px 0; text-align: center;"><a href="https://kabirahuja2431.github.io/">Website and CV
            template shamelessly copied from Kabir Ahuja</a></p>
        <p style="margin: 2px 0; text-align: center;"><a href="https://github.com/features/copilot">Website designed and
            developed by GPT-5 & Claude Sonnet-4 (GitHub Copilot)</a></p>
      </div>

    </div>
  </div>

</body>



<!-- <a href="https://www.annavignet.com/" target="_blank"> -->
<img src="images/yiyi.png" alt="Decorative illustration"
  style="position: fixed; bottom: 12px; right: 12px; width: 80px; height: auto; opacity: 0.85;">
<!-- </a> -->

<footer>
  <div class="container" style="text-align:center; padding: 12px 0 20px; color: inherit;">
    <small class="footer-note">¬© <span data-current-year></span> Varun Gumma. All rights reserved.</small>
  </div>
</footer>

<script>
  (function () {
    const prefersReduced = window.matchMedia('(prefers-reduced-motion: reduce)').matches;
    if (prefersReduced) return;
    const content = document.querySelector('.container.content');
    if (!content) return;
    const items = Array.from(content.children);
    items.forEach((el, i) => {
      el.classList.add('reveal');
      el.style.transitionDelay = (Math.min(i, 6) * 60) + 'ms';
    });
    const io = new IntersectionObserver((entries) => {
      entries.forEach(e => {
        if (e.isIntersecting) {
          e.target.classList.add('visible');
          io.unobserve(e.target);
        }
      });
    }, { threshold: 0.08 });
    items.forEach(el => io.observe(el));
  })();
</script>
<script>
  (function () {
    var btn = document.getElementById('theme-toggle');
    if (!btn) return;
    function setTheme(t) {
      document.documentElement.setAttribute('data-theme', t);
      try { localStorage.setItem('theme', t); } catch (e) { }
      var icon = btn.querySelector('i');
      if (icon) {
        icon.classList.remove('fa-sun', 'fa-moon');
        icon.classList.add(t === 'dark' ? 'fa-sun' : 'fa-moon');
      }
    }
    var current = document.documentElement.getAttribute('data-theme') || 'light';
    setTheme(current);
    btn.addEventListener('click', function () { setTheme((document.documentElement.getAttribute('data-theme') === 'dark') ? 'light' : 'dark'); });
  })();

  (function () {
    var year = new Date().getFullYear();
    var targets = document.querySelectorAll('[data-current-year]');
    targets.forEach(function (span) { span.textContent = year; });
  })();
</script>