<!DOCTYPE html>
<link rel="preconnect" href="https://rsms.me/">
<link rel="stylesheet" href="https://rsms.me/inter/inter.css">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<link
  href="https://fonts.googleapis.com/css2?family=Alegreya+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;0,800;0,900;1,100;1,300;1,400;1,500;1,700;1,800;1,900&family=Inconsolata:wght@200..900&family=Nunito:ital,wght@0,300;1,300&family=Raleway:ital,wght@0,100..900;1,100..900&family=Reddit+Mono:wght@200..900&family=Reddit+Sans:ital,wght@0,200..900;1,200..900&display=swap"
  rel="stylesheet">

<html lang="en">

<head>
  <title>Varun Gumma</title>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="blog, accent, Varun Gumma, jekyll">
  <meta name="author" content="">



  <meta name="description" content="">
  <link href='https://fonts.googleapis.com/css?family=Inconsolata:400,700' rel='stylesheet' type='text/css'>
  <link rel="alternate" type="application/rss+xml" title="Varun Gumma RSS" href="feed.xml" />
  <link rel="stylesheet" href="css/main.css">


  <!-- Facebook Open Graph -->
  <meta name="og:description" content="">
  <meta name="og:title" content="Varun Gumma">
  <meta name="og:url" content="https://varungumma.github.io/">
  <meta name="og:type" content="article">


  <!-- Twitter -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Varun Gumma">
  <meta name="twitter:description" content="">
  <meta name="twitter:url" content="https://varungumma.github.io/">

  <meta name="twitter:image" content="">

</head>

<body>
  <div class="wrapper">
    <div class="navbar container">

      <img id="ins-logo" src="images/uw.png" />


      <a id="author-name" class="alignable pull-left" href="https://varungumma.github.io">Varun Gumma</a>
      <ul id="navlist" class="alignable pull-right navbar-ul">


        <li class="alignable pull-left nav-list"><a href="">About</a>


          /

        </li>


        <li class="alignable pull-left nav-list"><a href="publications.html">Publications</a>


          /

        </li>


        <li class="alignable pull-left nav-list"><a target="_blank" href="CV.pdf">Resume</a>

      </ul>
    </div>
    <div style="clear:both"></div>
    <hr>

    <div class="container content">

      <p><img class="profile-picture" src="images/profile_pic.jpg" /></p>

      <p>Heyüëã! I am Varun, a Pre-Doctoral SCAI-Center Fellow at Microsoft Research India, where I am fortunate to work
        with <a href="https://www.microsoft.com/en-us/research/people/kalikab/"> Dr. Kalika Bali</a> and <a
          href="https://www.microsoft.com/en-us/research/people/susitara/"> Dr. Sunayana Sitaram</a>. Prior to this, I
        was a Master's Student at <a href="https://ai4bharat.iitm.ac.in/"> AI4Bharat</a> and <a
          href="https://ai4bharat.iitm.ac.in/">IIT Madras</a>, where I was
        co-advised by <a href="https://prajdabre.github.io/"> Dr. Raj Dabre</a> and <a
          href="https://www.cse.iitm.ac.in/~miteshk/"> Prof. Mitesh Khapra</a>. For what feels like eons
        ago now, I did my undergraduate studies at <a href="https://www.bits-pilani.ac.in/hyderabad/">BITS
          Hyderabad</a>, where I graduated with a B.E in Computer
        Science and a Minor in Physics.</p>

      <h2 id="research-interests">Research Interests</h2>

      <p>I am broadly interested in Natural Language Processing (NLP), particularly in areas such as Multilinguality
        combined with Machine Translation, Model Efficiency, Reasoning, and the Evaluation of Large Language Models. My
        research encompasses several specific areas and research questions:</p>

      <p><strong> üóé Document-Level Machine Translation</strong> How can we design or adapt existing Machine Translation
        models to translate entire documents reliably and efficiently? In a <a
          href="https://arxiv.org/abs/2408.11382">recent study</a>, I explored a rudimentary approach of replacing the
        Positional Embeddings of a standard pretrained Transformer with ones that facilitate length-generalization. This
        method demonstrated significant improvements in long-context understanding and generation with minimal
        fine-tuning. A subsequent question I am exploring is: how can we develop suitable evaluation metrics for
        document-level translation that effectively capture the task's nuances and provide a more reliable measure of
        model performance? Emphasis is placed on addressing issues such as "translationese" and "coreference-resolution"
        that challenge current metrics. With the prevalence of Large Language Models (LLMs) and Instruction-Tuning, it
        is also intriguing to investigate how these challenges can be addressed through "steerable" generation
        techniques in LLMs.</p>

      <p><strong>‚öôÔ∏è Model Efficiency</strong> My interest in model efficiency began with my <a
          href="https://aclanthology.org/2023.eamt-1.11/">Master's Thesis</a> on Knowledge Distillation for Multilingual
        Machine Translation models, where I investigated the impact of architectural variants like Extreme Parameter
        Sharing, Language-Specific Parameter Augmentation, and the Width-vs-Height trade-off on model performance,
        achieving gains with minimal parameter overhead (<a
          href="https://github.com/VarunGumma/fairseq/">framework</a>). With the advent of LLMs, I am now interested in
        exploring techniques such as Adaptive Tokenization, KV-Cache Compression, Mixture-of-Experts, and Efficient
        Long-Range Attention mechanisms to make LLM training and inference faster and less computationally expensive.
      </p>

      <p><strong>‚öñÔ∏è Evaluations</strong> The extensive use of internet data for training LLMs has led to "contamination"
        in standard benchmarks (<a href="https://arxiv.org/abs/2410.16186">EvalEval 2024</a>). Therefore, it is
        essential to continuously develop evaluation benchmarks and metrics that enable a holistic assessment of these
        models. Standard metrics are inadequate for multi-dimensional assessments of creative and open-ended
        generations, making LLM-based evaluators a preferred choice. However, our previous work reveals a clear
        disparity in the performance of LLM-based evaluators across languages, tasks, and perturbations (<a
          href="https://aclanthology.org/2024.findings-eacl.71/">EACL 2024</a>, <a
          href="https://aclanthology.org/2024.findings-naacl.148/">NAACL 2024</a>, <a
          href="https://arxiv.org/abs/2406.15053">EMNLP 2024</a>, <a href="https://arxiv.org/abs/2410.13671">ArXiv
          2024</a>). Thus, developing robust and "rational" multilingual evaluators is crucial. I believe that enhancing
        LLMs with strong reasoning abilities could significantly improve the reliability and interpretability of
        evaluations, and I am keen to explore how to build and "meta-evaluate" such models that can reason over outputs
        and offer a more robust assessment.</p>

      <!-- <p>I am broadly interested in Natural Language Processing (NLP), mainly towards Multilinguality clubbed with
        Machine Translation, Model Efficiency, Reasoning and Evaluation of Large Language Models. Some specific areas
        and Research Questions I am interested in are:</p>

      <p><strong> üóé Document-Level Machine Translation</strong> How can we build or modify exsisting Machine
        Translation models to translate entire documents reliablely and efficently? In a <a
          href="https://arxiv.org/abs/2408.11382"> recent work</a>, I explored a rudimentary of switching out Positional
        Embeddings of a standard pretrained Transformer with ones that favour length-generalization and showed that it
        can lead to significant improvements in long-context understanding and generation with minimal finetuning. I
        consequent question I am
        pondering on is how can we develop suitable evaluation metrics for document-level translation that can capture
        the nuances of the task and provide a more reliable measure of model performance, with more emphasis on the
        mitigating "translationese" and "coreference-resolution" issues that plague current metrics. With the ubiquity
        of Large
        Language Models (LLMs) and Instruction-Tuning, it would be interesting to also explore how much of these
        problems can be solved by LLMs with "Steerable"
        Generations.
      </p>

      <p><strong>‚öôÔ∏è Model Efficiency</strong> I was first introduced to this problem when I was working on my
        <a href="https://aclanthology.org/2023.eamt-1.11/">Master's Thesis</a> on Knowledge Distillation for
        Multilingual Machine Translation models, in which I explored how simple architectural variants like Extreme
        Parameter Sharing, Language-Specific Parameter Augmentation and Width-vs-Height trade-off can lead to various
        gains or
        drops in model performance at the cost of minimal parameter overhead (<a
          href="https://github.com/VarunGumma/fairseq/">framework</a>)
        Once again, with the advent of LLMs, I am interested to explore methods like Adaptive
        Tokenization, KV-Cache Compression, Mixture-of-Experts, and Efficient Long-Range Attention mechanisms to make
        training and inference of LLMs faster and computationally less expensive.
      </p>

      <p><strong>‚öñÔ∏è Evaluations</strong> The rampant consumption of data on the internet to train LLMs has lead to the
        "contamination" of standard banchmarks (<a href="https://arxiv.org/abs/2410.16186">EvalEval 2024</a>). Hence, it
        is vital to continually develop evaluation benchmarks
        and metrics for holistic evaluation of these models. Standard Metrics are unfit for a multi-dimensional
        assessment
        creative and open-ended generations, which is when we have to resort of LLM-based Evaluators. However, in our
        previous works we found that there is a clear disparity in the performance of LLM-based evaluators across
        languages, tasks and perturbations (<a href="https://aclanthology.org/2024.findings-eacl.71/">EACL 2024</a>, <a
          href="https://aclanthology.org/2024.findings-naacl.148/">NAACL 2024</a>, <a
          href="https://arxiv.org/abs/2406.15053">EMNLP 2024</a>, <a href="https://arxiv.org/abs/2410.13671">ArXiv
          2024</a>). Therefore, it is important to develop more robust and
        "rational"
        multilingual evaluators. I
        believe that inducing strong-reasoning abilities in LLMs could bolster the development of such evaluators, and I
        am
        interested in exploring how we can build and "meta-evaluate" such models that can reason over the output
        and provide a more
        reliable and interpretable evaluation.
      </p> -->

      <p>For a full list of my publications you can have a look <a href="publications.html">here</a>. Please feel free
        to reach out to me over <a href="mailto:varun230999@gmail.com">email</a> if you have any questions about my
        research.</p>

      <h2 id="news">News</h2>

      <ul>
        <li>
          <p><strong>2024-11-10</strong>: ‚úàÔ∏è Attending EMNLP 2024 at Miami, Florida to present our work, <a
              href="https://arxiv.org/abs/2406.15053">Pariksha</a>. I am also applying for a PhD this cycle (for Fall
            2025), so looking
            forward to connect with prospective mentors.</p>
        </li>
        <li>
          <p><strong>2024-10-21</strong>: üìúThe Report on Contamination of Multilingual Benchmarks has been accepted at
            EvalEval @ NEURIPS 2024. The
            <a href="https://arxiv.org/abs/2410.16186">preprint</a> is live!
          </p>
        </li>
        <li>
          <p><strong>2024-10-18</strong>: üìú Preprint for <a href="https://arxiv.org/abs/2410.13671">Health-Pariksha</a>
            in online. Do check it out, and more models are on the way! Also, version 2 of <a
              href="https://arxiv.org/abs/2408.11382">Towards Inducing Document-Level Abilities in MNMT Systems</a> is
            online, with an improved name, write up, evaluation set and <a
              href="https://github.com/VarunGumma/fairseq">framework</a>.</p>
        </li>
        <li>
          <p><strong>2024-08-10</strong>: ‚úàÔ∏è Attending ACL 2024 at Bangkok, Thailand (my first ever conference üéâ).</p>
        </li>
        <li>
          <p><strong>2023-07-31</strong>: ‚Ü™Ô∏è Converted from Intern to SCAI Center Fellow at Microsoft Research
            India</a>.
          </p>
        </li>
        <li>
          <p><strong>2023-05-22</strong>: ‚ñ∂Ô∏è Started my Internship at Microsoft Research India.</p>
        </li>
      </ul>

      <h2 id="teaching">Teaching</h2>
      <p><strong>Courses</strong></p>
      <ul>
        <li>TA‚Äôd for "Machine Learning", "Linear Algebra and Random Processes", and "Fundamentals of Deep Learning" at
          IIT Madras. Won the ‚≠ê TA Award for both first and second year of M.Tech.
        </li>
        <li>TA‚Äôd for "Introductary Physics", "Computer Programming", "Discerete Mathematics", "Data Structures and
          Algorithms", "Foundatios of Data Science" and "Machine Learning" at BITS Hyderabad.
        </li>
      </ul>

      <!-- <p><strong>Talks and Tutorials</strong></p>
      <ul>
        <li>
          <p>Tutorial on <a href="https://aclanthology.org/2023.acl-tutorials.3/">Everything you need to know about
              Multilingual LLMs:
              Towards fair, performant and reliable models for languages of the world</a> at <strong>ACL 2023</strong>.
            Tutorial slides available <a
              href="https://www.microsoft.com/en-us/research/uploads/prod/2023/07/ACL2023MultilingualModelsTutorial.pdf">here</a>.
          </p>
        </li>
        <li>
          <p>Talk on multilingual evaluation of large language models for the Microsoft Africa Research Institute‚Äôs
            research seminar . Recording available <a
              href="https://www.microsoft.com/en-us/research/video/multilingual-evaluation-of-generative-ai-mega/">here</a>.
          </p>
        </li>
      </ul> -->

      <hr />
      <div class="social-icons">
        <a href="mailto:varun230999@gmail.com" target="_blank"><i class="fas fa-envelope ai-lg"></i></a>
        <a href="https://scholar.google.com/citations?user=tqDhGbwAAAAJ&hl=en" target="_blank"><i
            class="ai ai-google-scholar ai-lg"></i></a>
        <a href="https://www.semanticscholar.org/author/Varun-Gumma/2140408530" target="_blank"><i
            class="ai ai-semantic-scholar ai-lg"></i></a>
        <a href="https://github.com/VarunGumma" target="_blank"><i class="fab fa-github ai-lg"></i></a>
        <a href="https://x.com/VarunGumma23" target="_blank"><i class="fab fa-twitter ai-lg"></i></a>
      </div>
      <p style="text-align: center; margin-bottom: 10px">
        <a href="https://github.com/ankitsultana" style="color: black"><small>Theme by Ankit Sultana.</small></a> <a
          href="https://kabirahuja2431.github.io/" style="color: black"><small>Website verbatim shamelessly copied from
            Kabir Ahuja</small></a>
      </p>

    </div>
  </div>

</body>



<!-- <a href="https://www.annavignet.com/" target="_blank"> -->
<img src="images/yiyi.png" alt="Description of the image"
  style="position: fixed; bottom: 0; right: 0; width: 80px; height: auto;">
<!-- </a> -->

<footer>

</footer>